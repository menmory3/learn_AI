
// custom_transpose.cpp

// custom_transpose.cpp

#include <torch/extension.h>
#include <ATen/ATen.h>
#include <ATen/cuda/CUDAContext.h>

// å£°æ˜ launcher
template <typename T>
void transpose_nchw_to_nhwc_launcher(
    const T* input,
    T* output,
    int N, int C, int H, int W,
    cudaStream_t stream);

at::Tensor transpose_nchw_to_nhwc_cuda(const at::Tensor& input) {
    TORCH_CHECK(input.dim() == 4, "Input must be a 4D tensor");
    TORCH_CHECK(input.is_cuda(), "Input must be a CUDA tensor");

    auto options = input.options().dtype(input.scalar_type());
    

    const int N = input.size(0);
    const int C = input.size(1);
    const int H = input.size(2);
    const int W = input.size(3);

    // ğŸ‘‡ æ­£ç¡®æ„é€  NHWC çš„ shape
    std::vector<int64_t> sizes{N, H, W, C};

    // åˆ›å»ºè¾“å‡ºå¼ é‡
    auto output = at::empty(sizes, input.options());

    cudaStream_t stream = at::cuda::getCurrentCUDAStream();

    // æ‰‹åŠ¨åˆ†å‘ï¼šæ ¹æ® scalar_type å®ä¾‹åŒ–å¯¹åº” kernel
    switch (input.scalar_type()) {
        case at::ScalarType::Float:
            transpose_nchw_to_nhwc_launcher<float>(
                input.data_ptr<float>(),
                output.data_ptr<float>(),
                N, C, H, W,
                stream);
            break;

        case at::ScalarType::Half:
            transpose_nchw_to_nhwc_launcher<at::Half>(
                input.data_ptr<at::Half>(),
                output.data_ptr<at::Half>(),
                N, C, H, W,
                stream);
            break;

        case at::ScalarType::Char:  // int8_t
            transpose_nchw_to_nhwc_launcher<int8_t>(
                input.data_ptr<int8_t>(),
                output.data_ptr<int8_t>(),
                N, C, H, W,
                stream);
            break;

        case at::ScalarType::QInt8:  // qint8
            transpose_nchw_to_nhwc_launcher<int8_t>(
                input.data_ptr<int8_t>(),
                output.data_ptr<int8_t>(),
                N, C, H, W,
                stream);
            break;

        default:
            AT_ERROR("transpose_nchw_to_nhwc_cuda not implemented for ", input.scalar_type());
    }

    return output;
}

// custom_transpose.cpp æœ€åæ·»åŠ ï¼š
PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.def("transpose_nchw_to_nhwc", &transpose_nchw_to_nhwc_cuda, "NCHW to NHWC transpose (CUDA)");
}